{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Gender Classification using CNN"},{"metadata":{},"cell_type":"markdown","source":"Представляю вашему вниманию мой первый опыт обучения нейронных сетей. Работа была проделана меньше чем за неделю без никакого бэкграунда в нейронных сетях, я только делал классический МЛ. Здесь я расскажу общую архитектуру модели, внизу же про проблемы с которыми столкнулся и как их решал, какие методы можно применить, чтобы решить оставшиеся.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2    \nfrom sklearn.metrics import f1_score\nimport glob\nfrom keras.preprocessing import image\nfrom keras.models import Sequential, Model\nfrom keras.utils import to_categorical\nfrom keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, Flatten, Dense, Dropout, Activation , Concatenate, Input , BatchNormalization, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator ,img_to_array, load_img\nfrom keras.preprocessing import image\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.optimizers import SGD\nfrom keras.utils import plot_model\nfrom keras import Model\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Предобработка данных\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/nikitapupu/data (1).csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nd = [0]*50000\nnr = [1]*25001\nny = [2]*25001\nnt = nd+nr+ny","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datar = pd.DataFrame(nt, columns=['partition'])","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_par_attr = df.join(datar)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_par_attr.set_index('path', inplace=True)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Тут всего лишь вместо индекса делаю названия картинок, чтобы потом иметь доступ на их путь, маркирую под пол ('label') и делю на\npartition\n        0 -> train\n        1 -> validation\n        2 -> test"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_par_attr","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                   label  partition\npath                               \nmale/085992.jpg        0          0\nmale/046332.jpg        0          0\nfemale/097359.jpg      1          0\nfemale/170442.jpg      1          0\nmale/008056.jpg        0          0\n...                  ...        ...\nfemale/174616.jpg      1          2\nfemale/177533.jpg      1          2\nmale/095538.jpg        0          2\nfemale/029444.jpg      1          2\nfemale/065885.jpg      1          2\n\n[100002 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>partition</th>\n    </tr>\n    <tr>\n      <th>path</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>male/085992.jpg</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>male/046332.jpg</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>female/097359.jpg</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>female/170442.jpg</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>male/008056.jpg</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>female/174616.jpg</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>female/177533.jpg</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>male/095538.jpg</th>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>female/029444.jpg</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>female/065885.jpg</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>100002 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Предобработка данных: функция для перевода картинок в матрицы"},{"metadata":{"trusted":true},"cell_type":"code","source":"images_folder = \"../input/ntechdata/internship_data/\"\ndef load_reshape_img(fname):\n    img = load_img(fname, target_size = (224, 224), color_mode='rgb')\n    x = img_to_array(img)/255.\n    x = x.reshape((1,) + x.shape)\n\n    return x\n\nfrom keras.utils import np_utils\n\ndef generate_df(partition, attr, num_samples):\n    '''\n    partition\n        0 -> train\n        1 -> validation\n        2 -> test\n    \n    '''\n    \n    df_ = df_par_attr[(df_par_attr['partition'] == partition) \n                           & (df_par_attr[attr] == 0)].sample(int(num_samples/2))\n    df_ = pd.concat([df_,\n                      df_par_attr[(df_par_attr['partition'] == partition) \n                                  & (df_par_attr[attr] == 1)].sample(int(num_samples/2))])\n\n    # for Train and Validation\n    if partition != 2:\n        x_ = np.array([load_reshape_img(images_folder + fname) for fname in df_.index])\n        x_ = x_.reshape(x_.shape[0], 224, 224, 3)\n        y_ = np_utils.to_categorical(df_[attr],2)\n    # for Test\n    else:\n        x_ = []\n        y_ = []\n\n        for index, target in df_.iterrows():\n            im = cv2.imread(images_folder + index)\n            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n            im = np.expand_dims(im, axis =0)\n            x_.append(im)\n            y_.append(target[attr])\n\n    return x_, y_","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_SAMPLES = 10000\nVALIDATION_SAMPLES = 2500\nTEST_SAMPLES = 2500\nIMG_WIDTH = 224\nIMG_HEIGHT = 224\nBATCH_SIZE = 16\nNUM_EPOCHS = 4","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"### разделяю данные на test, train"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input\nx_train, y_train = generate_df(0, 'label', TRAINING_SAMPLES)\nimages_folder = \"../input/ntechdata/internship_data/\"\n# Train - Data Preparation - Data Augmentation with generators\ntrain_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n)\n\ntrain_datagen.fit(x_train)\n\ntrain_generator = train_datagen.flow(\nx_train, y_train,\nbatch_size=BATCH_SIZE,\n)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_valid, y_valid = generate_df(1, 'label', VALIDATION_SAMPLES)\n\nvalid_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n)\n\nvalid_datagen.fit(x_valid)\n\nvalid_generator = valid_datagen.flow(\nx_valid, y_valid,\nbatch_size=BATCH_SIZE,\n)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## архитектура модели - ResNet50 + предобученные веса\n### большая проблема при выполнении тестового была в том, что невозможно засунуть все 100к картинок в один массив np.array, поэтому я делал это сэмплами по 10к. То есть брал первые 10к,сохранял веса и на этих весах новые 10к и так 5-6 раз. \n### из-за такой архитектуры решения на последний день тяжело построить скрипт, нужный для тестового решения, который бы выдавал json файл. Только под конец я понял, что нужно строить функцию, которая может предсказывать дискретно, а не сэмплами по 10к, но было уже поздно. Первый опыт, который научил меня заранее продумывать архитектуру решения под задание, а не просто использовать best practices на каггле."},{"metadata":{"trusted":true},"cell_type":"code","source":"inc_model = ResNet50(weights='imagenet',\n                        include_top=False,\n                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\nprint(\"number of layers:\", len(inc_model.layers))\n#inc_model.summary()","execution_count":12,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 2s 0us/step\nnumber of layers: 175\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding custom Layers\nx = inc_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation=\"relu\")(x)\npredictions = Dense(2, activation=\"softmax\")(x)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ = Model(inputs=inc_model.input, outputs=predictions)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_.load_weights('../input/jhlsfg/Scurt_best_1.hdf5')","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating the final model \n\n\n\n\n# Lock initial layers to do not be trained\nfor layer in model_.layers[:52]:\n    layer.trainable = False\n\n# compile the model\n\nmodel_.compile(optimizer=SGD(lr=0.0001, momentum=0.9)\n                    , loss='binary_crossentropy'\n                    , metrics=['accuracy'])","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_path = \"../input/durtuso\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\ncheckpointer = ModelCheckpoint(filepath='orty.best.hdf5', \n                               verbose=1, save_weights_only=True, period = 1)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Обучаем"},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model_.fit_generator(train_generator\n                     , validation_data = valid_generator\n                      , steps_per_epoch= TRAINING_SAMPLES/BATCH_SIZE\n                      , epochs= NUM_EPOCHS\n                      , callbacks=[checkpointer]\n                      , verbose=1\n                            \n                    )","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/4\n625/625 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9191\nEpoch 00001: saving model to orty.best.hdf5\n625/625 [==============================] - 2218s 4s/step - loss: 0.2021 - accuracy: 0.9191 - val_loss: 0.1723 - val_accuracy: 0.9328\nEpoch 2/4\n 11/625 [..............................] - ETA: 31:11 - loss: 0.1812 - accuracy: 0.9205","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Как улучшить модель?\nИтак, модель обучается с метрикой **в 93.3%**\n- использовать все 100к картинок с помощью мЕньших сэмплов. Например, можно сделать сэмплы по 100 картинок и так пройти весь датасет. \n- экспериментировать со слоями - я мало этого делал, так как скорость моего программирования была очень маленькой из-за того, что я сталкиваюсь с такими вещами впервые\n- увеличить датасет с помощью augmentation\n"},{"metadata":{},"cell_type":"markdown","source":"## Почему я не успел сделать скрипт?\nКак я уже говорил, это моя первая нейронная сетка и меньше чем за неделю я столнулся с большим количеством проблем. Начиная с неправильной предобработкой в ImageDataGenerator из-за разного разрешения картинок, заканчивая не изменяющимся val_accuracy в процессе обучения из-за неправильной нормализации valid данных. Только в последние 3 часа я решил все проблемы и остался один на один с задачей построения скрипта в условиях усталости после **недельного спринта изучения tensorflow**. Чтобы успешно сделать скрипт, мне нужно поменять функцию generate_df так,чтобы можно было делать не сэмплы по 10к, но любое заданное количество картинок, на что я уже неспособен из-за усталости"},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\nДля меня сейчас начинается самая кайфовая часть - понять, что я вообще сделал с теоретической точки зрения? \nЭто я собираюсь сделать с помощью Deep Learning Illustrated by Krohn,и несмотря на любой результат тестового, я явно научился многому, в ситуации без дедлайна я бы не успел сделать так много"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}