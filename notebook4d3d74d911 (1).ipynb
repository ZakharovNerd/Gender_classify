{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2    \nfrom sklearn.metrics import f1_score\nimport glob\nfrom keras.preprocessing import image\nfrom keras.models import Sequential, Model\nfrom keras.utils import to_categorical\nfrom keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, Flatten, Dense, Dropout, Activation , Concatenate, Input , BatchNormalization, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator ,img_to_array, load_img\nfrom keras.preprocessing import image\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.optimizers import SGD\nfrom keras.utils import plot_model\nfrom keras import Model\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/nikitapupu/data (1).csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nd = [0]*50000\nnr = [1]*25001\nny = [2]*25001\nnt = nd+nr+ny","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datar = pd.DataFrame(nt, columns=['partition'])","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_par_attr = df.join(datar)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_par_attr.set_index('path', inplace=True)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_par_attr","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                   label  partition\npath                               \nmale/085992.jpg        0          0\nmale/046332.jpg        0          0\nfemale/097359.jpg      1          0\nfemale/170442.jpg      1          0\nmale/008056.jpg        0          0\n...                  ...        ...\nfemale/174616.jpg      1          2\nfemale/177533.jpg      1          2\nmale/095538.jpg        0          2\nfemale/029444.jpg      1          2\nfemale/065885.jpg      1          2\n\n[100002 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>partition</th>\n    </tr>\n    <tr>\n      <th>path</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>male/085992.jpg</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>male/046332.jpg</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>female/097359.jpg</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>female/170442.jpg</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>male/008056.jpg</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>female/174616.jpg</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>female/177533.jpg</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>male/095538.jpg</th>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>female/029444.jpg</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>female/065885.jpg</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>100002 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_folder = \"../input/ntechdata/internship_data/\"\ndef load_reshape_img(fname):\n    img = load_img(fname, target_size = (224, 224), color_mode='rgb')\n    x = img_to_array(img)/255.\n    x = x.reshape((1,) + x.shape)\n\n    return x\n\nfrom keras.utils import np_utils\n\ndef generate_df(partition, attr, num_samples):\n    '''\n    partition\n        0 -> train\n        1 -> validation\n        2 -> test\n    \n    '''\n    \n    df_ = df_par_attr[(df_par_attr['partition'] == partition) \n                           & (df_par_attr[attr] == 0)].sample(int(num_samples/2))\n    df_ = pd.concat([df_,\n                      df_par_attr[(df_par_attr['partition'] == partition) \n                                  & (df_par_attr[attr] == 1)].sample(int(num_samples/2))])\n\n    # for Train and Validation\n    if partition != 2:\n        x_ = np.array([load_reshape_img(images_folder + fname) for fname in df_.index])\n        x_ = x_.reshape(x_.shape[0], 224, 224, 3)\n        y_ = np_utils.to_categorical(df_[attr],2)\n    # for Test\n    else:\n        x_ = []\n        y_ = []\n\n        for index, target in df_.iterrows():\n            im = cv2.imread(images_folder + index)\n            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n            im = np.expand_dims(im, axis =0)\n            x_.append(im)\n            y_.append(target[attr])\n\n    return x_, y_","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_SAMPLES = 10000\nVALIDATION_SAMPLES = 2500\nTEST_SAMPLES = 2500\nIMG_WIDTH = 224\nIMG_HEIGHT = 224\nBATCH_SIZE = 16\nNUM_EPOCHS = 4","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input\nx_train, y_train = generate_df(0, 'label', TRAINING_SAMPLES)\nimages_folder = \"../input/ntechdata/internship_data/\"\n# Train - Data Preparation - Data Augmentation with generators\ntrain_datagen =  ImageDataGenerator(\n  preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n)\n\ntrain_datagen.fit(x_train)\n\ntrain_generator = train_datagen.flow(\nx_train, y_train,\nbatch_size=BATCH_SIZE,\n)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_valid, y_valid = generate_df(1, 'label', VALIDATION_SAMPLES)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inc_model = ResNet50(weights='imagenet',\n                        include_top=False,\n                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\nprint(\"number of layers:\", len(inc_model.layers))\n#inc_model.summary()","execution_count":12,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 2s 0us/step\nnumber of layers: 175\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding custom Layers\nx = inc_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation=\"relu\")(x)\npredictions = Dense(2, activation=\"softmax\")(x)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ = Model(inputs=inc_model.input, outputs=predictions)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_.load_weights('../input/jhlsfg/Scurt_best_1.hdf5')","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating the final model \n\n\n\n\n# Lock initial layers to do not be trained\nfor layer in model_.layers[:52]:\n    layer.trainable = False\n\n# compile the model\n\nmodel_.compile(optimizer=SGD(lr=0.0001, momentum=0.9)\n                    , loss='binary_crossentropy'\n                    , metrics=['accuracy'])","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_path = \"../input/durtuso\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\ncheckpointer = ModelCheckpoint(filepath='orty.best.hdf5', \n                               verbose=1, save_weights_only=True, period = 1)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model_.fit_generator(train_generator\n                     , validation_data = (x_valid, y_valid)\n                      , steps_per_epoch= TRAINING_SAMPLES/BATCH_SIZE\n                      , epochs= NUM_EPOCHS\n                      , callbacks=[checkpointer]\n                      , verbose=1\n                            \n                    )","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/4\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}